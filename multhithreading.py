# -*- coding: utf-8 -*-
"""multhithreading.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T7sWC-f46Flzw9xT6VoZiMHNz9XvqsWF
"""

import threading
from tqdm.notebook import tqdm, trange
import time    # to be used in loop iterations
import os
import itertools
import time
import random

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import seaborn as sns

def create_empty_dataframe(df):
    empty_df = pd.DataFrame(columns=[ np.float64(i) for i in range(len(df.columns))])
    # Chnage the names of the coloums 187 to class and 188 to label to reflect the original mitbih dataframe
    empty_df.rename(columns={187: 'class'}, inplace=True)
    empty_df.rename(columns={188: 'label'}, inplace=True)

    return empty_df
def fill_empty_with_synthetic_data(original_df,new_df):
    old_len = len(original_df)
    to_fill = 100000  - len(original_df)
    run_count = 0

    pbar = tqdm(total = to_fill+1)
    while(run_count < to_fill):
        for i in tqdm(range(len(original_df)), desc='orignial dataset'):
            new_list = original_df.iloc[i,:187]
            run_count = len(new_df)
            new_df.loc[run_count] = original_df.iloc[i].copy(deep=True)

            for y in range(187):
                if new_list[y] < 0.05 :
                    new_df.iloc[run_count,y] = new_list[y]
                else:
                    new_df.iloc[run_count,y] = new_list[y] - 0.05

            if( (run_count+len(original_df)) >= 100000):
                break
            #print(run_count)
        pbar.update(len(original_df))
    pbar.close()

from google.colab import drive
drive.mount('/content/drive')

df_mitbih_train = pd.read_csv(r"/content/sample_data/mnist_train_small.csv", header=None)
df_mitbih_test = pd.read_csv(r"/content/sample_data/mnist_test.csv", header=None)
df_mitbih = pd.concat([df_mitbih_train, df_mitbih_test], axis=0)
df_mitbih.rename(columns={187: 'class'}, inplace=True)

id_to_label = {
    0: "Normal",
    1: "Artial Premature",
    2: "Premature ventricular contraction",
    3: "Fusion of ventricular and normal",
    4: "Fusion of paced and normal"
}
df_mitbih['label'] = df_mitbih.iloc[:, -1].map(id_to_label)
print(df_mitbih.info())

df_fus_ven_nor_old = df_mitbih[df_mitbih['label'].str.contains(r"Fusion of ventricular and normal")].copy(deep=True)
df_fus_ven_nor = create_empty_dataframe(df_fus_ven_nor_old)

df_fus_pac_nor_old = df_mitbih[df_mitbih['label'].str.contains(r"Fusion of paced and normal")].copy(deep=True)
df_fus_pac_nor =  create_empty_dataframe(df_fus_pac_nor_old)

thread_fus_ven_nor = threading.Thread(target=fill_empty_with_synthetic_data, args=(df_fus_ven_nor_old, df_fus_ven_nor))
thread_fus_pac_nor = threading.Thread(target=fill_empty_with_synthetic_data, args=(df_fus_pac_nor_old, df_fus_pac_nor))

thread_fus_ven_nor.start()
thread_fus_pac_nor.start()

thread_fus_ven_nor.join()
thread_fus_pac_nor.join()

df_fus_ven_nor_f = pd.concat([df_fus_ven_nor_old, df_fus_ven_nor], axis=0)
print(len(df_fus_ven_nor_f))
df_fus_ven_nor_f.to_csv('fus_ven_nor.csv', index=False)

df_fus_pac_nor_f = pd.concat([df_fus_pac_nor_old, df_fus_pac_nor], axis=0)
print(len(df_fus_pac_nor_f))
df_fus_pac_nor_f.to_csv('fus_pac_nor.csv', index=False)

